# Glimpse ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ë° ë³µêµ¬ ê°€ì´ë“œ

## ğŸ—„ ê°œìš”

GlimpseëŠ” ì‚¬ìš©ìì˜ ë¯¼ê°í•œ ë°ì´í„°ë¥¼ ë‹¤ë£¨ëŠ” ë°ì´íŒ… ì•±ìœ¼ë¡œ, ë°ì´í„° ì†ì‹¤ì€ ì‹¬ê°í•œ ì„œë¹„ìŠ¤ ì¤‘ë‹¨ê³¼ ì‹ ë¢°ë„ í•˜ë½ìœ¼ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ë¬¸ì„œëŠ” PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ì˜ ë°±ì—… ë° ë³µêµ¬ ì „ëµì„ ìƒì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤.

### ë°±ì—… ëª©í‘œ
- **RPO (Recovery Point Objective)**: ìµœëŒ€ 1ì‹œê°„ì˜ ë°ì´í„° ì†ì‹¤ í—ˆìš©
- **RTO (Recovery Time Objective)**: ìµœëŒ€ 4ì‹œê°„ ë‚´ ë³µêµ¬
- **ë³´ê´€ ê¸°ê°„**: ì¼ì¼ ë°±ì—… 30ì¼, ì£¼ê°„ ë°±ì—… 12ì£¼, ì›”ê°„ ë°±ì—… 1ë…„

## ğŸ”„ ë°±ì—… ì „ëµ

### 1. ë°±ì—… ìœ í˜•

#### 1.1 ì „ì²´ ë°±ì—… (Full Backup)
```bash
# pg_dumpë¥¼ ì‚¬ìš©í•œ ì „ì²´ ë°±ì—…
pg_dump -h $DB_HOST -U $DB_USER -d glimpse_prod \
  --verbose \
  --format=custom \
  --compress=9 \
  --file=glimpse_full_$(date +%Y%m%d_%H%M%S).dump

# SQL í˜•ì‹ ë°±ì—… (ì½ê¸° ê°€ëŠ¥)
pg_dump -h $DB_HOST -U $DB_USER -d glimpse_prod \
  --verbose \
  --format=plain \
  --file=glimpse_full_$(date +%Y%m%d_%H%M%S).sql
```

#### 1.2 ì¦ë¶„ ë°±ì—… (WAL ì•„ì¹´ì´ë¹™)
```bash
# postgresql.conf ì„¤ì •
wal_level = replica
archive_mode = on
archive_command = 'test ! -f /backup/archive/%f && cp %p /backup/archive/%f'
archive_timeout = 300  # 5ë¶„ë§ˆë‹¤ ê°•ì œ ì•„ì¹´ì´ë¸Œ
```

#### 1.3 ìŠ¤ëƒ…ìƒ· ë°±ì—… (AWS RDS)
```bash
# RDS ìŠ¤ëƒ…ìƒ· ìƒì„±
aws rds create-db-snapshot \
  --db-instance-identifier glimpse-production \
  --db-snapshot-identifier glimpse-snapshot-$(date +%Y%m%d-%H%M%S) \
  --tags Key=Type,Value=Manual Key=Retention,Value=30days
```

### 2. ë°±ì—… ìë™í™”

#### 2.1 ë°±ì—… ìŠ¤í¬ë¦½íŠ¸
```bash
#!/bin/bash
# /opt/glimpse/scripts/backup-database.sh

set -euo pipefail

# ì„¤ì •
source /opt/glimpse/.env.production

BACKUP_ROOT="/backup/postgres"
S3_BUCKET="glimpse-backups"
RETENTION_DAYS=30
LOG_FILE="/var/log/glimpse/backup.log"
SLACK_WEBHOOK=$BACKUP_SLACK_WEBHOOK

# í•¨ìˆ˜: ë¡œê¹…
log() {
    echo "[$(date +'%Y-%m-%d %H:%M:%S')] $1" | tee -a $LOG_FILE
}

# í•¨ìˆ˜: Slack ì•Œë¦¼
notify_slack() {
    local status=$1
    local message=$2
    local color=${3:-"#36a64f"}
    
    curl -X POST $SLACK_WEBHOOK \
      -H 'Content-Type: application/json' \
      -d "{
        \"attachments\": [{
          \"color\": \"$color\",
          \"title\": \"Database Backup $status\",
          \"text\": \"$message\",
          \"footer\": \"Glimpse Backup System\",
          \"ts\": $(date +%s)
        }]
      }"
}

# í•¨ìˆ˜: ë°±ì—… ì‹¤í–‰
perform_backup() {
    local backup_type=$1
    local timestamp=$(date +%Y%m%d_%H%M%S)
    local backup_dir="$BACKUP_ROOT/$backup_type/$(date +%Y/%m)"
    local backup_file="glimpse_${backup_type}_${timestamp}.dump"
    local backup_path="$backup_dir/$backup_file"
    
    # ë””ë ‰í† ë¦¬ ìƒì„±
    mkdir -p $backup_dir
    
    log "Starting $backup_type backup: $backup_file"
    
    # ë°±ì—… ì‹¤í–‰
    PGPASSWORD=$DB_PASSWORD pg_dump \
        -h $DB_HOST \
        -U $DB_USER \
        -d $DB_NAME \
        --verbose \
        --format=custom \
        --compress=9 \
        --jobs=4 \
        --file=$backup_path \
        2>&1 | tee -a $LOG_FILE
    
    # ë°±ì—… ê²€ì¦
    if [ -f $backup_path ]; then
        local size=$(du -h $backup_path | cut -f1)
        log "Backup completed: $backup_file (Size: $size)"
        
        # ì²´í¬ì„¬ ìƒì„±
        sha256sum $backup_path > ${backup_path}.sha256
        
        # S3 ì—…ë¡œë“œ
        aws s3 cp $backup_path s3://$S3_BUCKET/database/$backup_type/ \
            --storage-class STANDARD_IA
        aws s3 cp ${backup_path}.sha256 s3://$S3_BUCKET/database/$backup_type/
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        echo "{
            \"timestamp\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\",
            \"type\": \"$backup_type\",
            \"file\": \"$backup_file\",
            \"size\": \"$size\",
            \"checksum\": \"$(cat ${backup_path}.sha256 | cut -d' ' -f1)\",
            \"db_version\": \"$(psql -h $DB_HOST -U $DB_USER -d $DB_NAME -t -c 'SELECT version()')\"
        }" > ${backup_path}.json
        
        aws s3 cp ${backup_path}.json s3://$S3_BUCKET/database/$backup_type/
        
        return 0
    else
        log "ERROR: Backup failed for $backup_file"
        return 1
    fi
}

# í•¨ìˆ˜: ë¡œì»¬ ë°±ì—… ì •ë¦¬
cleanup_local_backups() {
    log "Cleaning up local backups older than $RETENTION_DAYS days"
    
    find $BACKUP_ROOT -name "*.dump" -mtime +$RETENTION_DAYS -delete
    find $BACKUP_ROOT -name "*.sha256" -mtime +$RETENTION_DAYS -delete
    find $BACKUP_ROOT -name "*.json" -mtime +$RETENTION_DAYS -delete
    
    # ë¹ˆ ë””ë ‰í† ë¦¬ ì •ë¦¬
    find $BACKUP_ROOT -type d -empty -delete
}

# í•¨ìˆ˜: S3 ë°±ì—… ì •ë¦¬
cleanup_s3_backups() {
    log "Cleaning up S3 backups based on lifecycle policy"
    
    # Daily backups: 30ì¼ ì´ìƒ ì‚­ì œ
    aws s3 ls s3://$S3_BUCKET/database/daily/ --recursive | \
    while read -r line; do
        createDate=$(echo $line | awk '{print $1" "$2}')
        createDate=$(date -d "$createDate" +%s)
        olderThan=$(date -d "30 days ago" +%s)
        if [[ $createDate -lt $olderThan ]]; then
            fileName=$(echo $line | awk '{print $4}')
            aws s3 rm s3://$S3_BUCKET/$fileName
        fi
    done
}

# ë©”ì¸ ì‹¤í–‰
main() {
    log "=== Database backup started ==="
    
    # ë°±ì—… ì¢…ë¥˜ ê²°ì •
    DAY_OF_WEEK=$(date +%u)
    DAY_OF_MONTH=$(date +%d)
    
    if [ "$DAY_OF_MONTH" -eq "01" ]; then
        BACKUP_TYPE="monthly"
    elif [ "$DAY_OF_WEEK" -eq "7" ]; then
        BACKUP_TYPE="weekly"
    else
        BACKUP_TYPE="daily"
    fi
    
    # ë°±ì—… ì‹¤í–‰
    if perform_backup $BACKUP_TYPE; then
        notify_slack "SUCCESS" "Database backup completed successfully (Type: $BACKUP_TYPE)"
        
        # ì •ë¦¬ ì‘ì—…
        cleanup_local_backups
        cleanup_s3_backups
        
        log "=== Database backup completed successfully ==="
        exit 0
    else
        notify_slack "FAILED" "Database backup failed! Please check immediately." "#ff0000"
        log "=== Database backup failed ==="
        exit 1
    fi
}

# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
main
```

#### 2.2 Cron ìŠ¤ì¼€ì¤„ ì„¤ì •
```bash
# /etc/cron.d/glimpse-backup
SHELL=/bin/bash
PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin

# ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… (ë§¤ì¼ ìƒˆë²½ 2ì‹œ)
0 2 * * * postgres /opt/glimpse/scripts/backup-database.sh >> /var/log/glimpse/backup-cron.log 2>&1

# WAL ì•„ì¹´ì´ë¸Œ í™•ì¸ (ë§¤ì‹œê°„)
0 * * * * postgres /opt/glimpse/scripts/check-wal-archive.sh

# ë°±ì—… ìƒíƒœ ë¦¬í¬íŠ¸ (ë§¤ì¼ ì˜¤ì „ 9ì‹œ)
0 9 * * * postgres /opt/glimpse/scripts/backup-report.sh
```

### 3. ë°±ì—… ê²€ì¦

#### 3.1 ìë™ ë°±ì—… ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
```bash
#!/bin/bash
# /opt/glimpse/scripts/verify-backup.sh

set -euo pipefail

verify_backup() {
    local backup_file=$1
    local temp_db="glimpse_verify_$(date +%s)"
    
    echo "Verifying backup: $backup_file"
    
    # ì„ì‹œ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
    createdb -h localhost -U postgres $temp_db
    
    # ë°±ì—… ë³µì› ì‹œë„
    if pg_restore -h localhost -U postgres -d $temp_db $backup_file; then
        # ê¸°ë³¸ ê²€ì¦ ì¿¼ë¦¬
        TABLES=$(psql -h localhost -U postgres -d $temp_db -t -c "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema='public'")
        USERS=$(psql -h localhost -U postgres -d $temp_db -t -c "SELECT COUNT(*) FROM users")
        
        echo "Verification passed: Tables=$TABLES, Users=$USERS"
        
        # ì„ì‹œ ë°ì´í„°ë² ì´ìŠ¤ ì‚­ì œ
        dropdb -h localhost -U postgres $temp_db
        
        return 0
    else
        echo "Verification failed!"
        dropdb -h localhost -U postgres $temp_db 2>/dev/null || true
        return 1
    fi
}

# ìµœì‹  ë°±ì—… íŒŒì¼ ê²€ì¦
LATEST_BACKUP=$(find /backup/postgres/daily -name "*.dump" -mtime -1 | head -1)
if [ -n "$LATEST_BACKUP" ]; then
    verify_backup $LATEST_BACKUP
fi
```

## ğŸ” ë³µêµ¬ ì ˆì°¨

### 1. ë³µêµ¬ ì‹œë‚˜ë¦¬ì˜¤ë³„ ëŒ€ì‘

#### 1.1 ë…¼ë¦¬ì  ì†ìƒ ë³µêµ¬ (ì˜ëª»ëœ ë°ì´í„° ìˆ˜ì •/ì‚­ì œ)
```bash
#!/bin/bash
# /opt/glimpse/scripts/point-in-time-recovery.sh

# íŠ¹ì • ì‹œì ìœ¼ë¡œ ë³µêµ¬
RECOVERY_TIME="2024-01-31 14:30:00"
BACKUP_FILE="/backup/postgres/daily/glimpse_daily_20240131_020000.dump"

# 1. í˜„ì¬ ìƒíƒœ ë°±ì—…
pg_dump -h $DB_HOST -U $DB_USER -d glimpse_prod > pre_recovery_backup.sql

# 2. ìƒˆ ë°ì´í„°ë² ì´ìŠ¤ì— ë³µì›
createdb -h $DB_HOST -U $DB_USER glimpse_recovery
pg_restore -h $DB_HOST -U $DB_USER -d glimpse_recovery $BACKUP_FILE

# 3. WAL ì ìš©ìœ¼ë¡œ íŠ¹ì • ì‹œì ê¹Œì§€ ë³µêµ¬
psql -h $DB_HOST -U $DB_USER -d glimpse_recovery << EOF
-- recovery.conf ì„¤ì • (PostgreSQL 12 ì´ìƒì€ postgresql.confì—)
recovery_target_time = '$RECOVERY_TIME'
recovery_target_action = 'promote'
EOF

# 4. ë°ì´í„° ê²€ì¦
echo "ë³µêµ¬ëœ ë°ì´í„° ê²€ì¦:"
psql -h $DB_HOST -U $DB_USER -d glimpse_recovery -c "
SELECT 
    'Users' as table_name, COUNT(*) as count FROM users
UNION ALL
SELECT 'Matches', COUNT(*) FROM matches
UNION ALL
SELECT 'Messages', COUNT(*) FROM messages;
"

# 5. í”„ë¡œë•ì…˜ ì „í™˜ ì¤€ë¹„
echo "ë³µêµ¬ê°€ ì™„ë£Œë˜ë©´ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì „í™˜í•˜ì„¸ìš”:"
echo "ALTER DATABASE glimpse_prod RENAME TO glimpse_prod_old;"
echo "ALTER DATABASE glimpse_recovery RENAME TO glimpse_prod;"
```

#### 1.2 ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ ë³µêµ¬
```bash
#!/bin/bash
# /opt/glimpse/scripts/full-recovery.sh

set -euo pipefail

# ì„¤ì •
BACKUP_SOURCE="s3"  # local ë˜ëŠ” s3
RECOVERY_DATE=$1    # YYYYMMDD í˜•ì‹

if [ -z "$RECOVERY_DATE" ]; then
    echo "Usage: $0 YYYYMMDD"
    exit 1
fi

# S3ì—ì„œ ë°±ì—… ëª©ë¡ ì¡°íšŒ
echo "Available backups for $RECOVERY_DATE:"
aws s3 ls s3://glimpse-backups/database/daily/ | grep $RECOVERY_DATE

read -p "Enter backup filename: " BACKUP_FILE

# ë°±ì—… ë‹¤ìš´ë¡œë“œ
echo "Downloading backup..."
aws s3 cp s3://glimpse-backups/database/daily/$BACKUP_FILE /tmp/
aws s3 cp s3://glimpse-backups/database/daily/${BACKUP_FILE}.sha256 /tmp/

# ì²´í¬ì„¬ ê²€ì¦
echo "Verifying checksum..."
cd /tmp && sha256sum -c ${BACKUP_FILE}.sha256

# ì„œë¹„ìŠ¤ ì¤‘ë‹¨
echo "Stopping application services..."
systemctl stop glimpse-api

# ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…
echo "Backing up current database..."
pg_dump -h $DB_HOST -U $DB_USER -d glimpse_prod > glimpse_prod_before_recovery.sql

# ë°ì´í„°ë² ì´ìŠ¤ ì‚­ì œ ë° ì¬ìƒì„±
echo "Recreating database..."
dropdb -h $DB_HOST -U $DB_USER glimpse_prod
createdb -h $DB_HOST -U $DB_USER glimpse_prod

# ë°±ì—… ë³µì›
echo "Restoring backup..."
pg_restore -h $DB_HOST -U $DB_USER -d glimpse_prod -j 4 /tmp/$BACKUP_FILE

# í†µê³„ ì—…ë°ì´íŠ¸
echo "Updating statistics..."
psql -h $DB_HOST -U $DB_USER -d glimpse_prod -c "ANALYZE;"

# ì„œë¹„ìŠ¤ ì‹œì‘
echo "Starting application services..."
systemctl start glimpse-api

# í—¬ìŠ¤ì²´í¬
sleep 10
curl -f http://localhost:3000/health || echo "Health check failed!"

echo "Recovery completed!"
```

### 2. ì¬í•´ ë³µêµ¬ (DR)

#### 2.1 ëŒ€ê¸° ì„œë²„ ì„¤ì • (Streaming Replication)
```bash
# Primary ì„œë²„ ì„¤ì • (postgresql.conf)
wal_level = replica
max_wal_senders = 3
wal_keep_segments = 64
hot_standby = on

# Standby ì„œë²„ ì„¤ì •
# 1. ë² ì´ìŠ¤ ë°±ì—…
pg_basebackup -h primary_host -D /var/lib/postgresql/data -U replicator -W -P -X stream

# 2. recovery.conf (PostgreSQL 11 ì´í•˜) ë˜ëŠ” postgresql.auto.conf (PostgreSQL 12+)
standby_mode = 'on'
primary_conninfo = 'host=primary_host port=5432 user=replicator'
restore_command = 'cp /archive/%f %p'
```

#### 2.2 í˜ì¼ì˜¤ë²„ ì ˆì°¨
```bash
#!/bin/bash
# /opt/glimpse/scripts/failover.sh

# 1. Primary ì„œë²„ í™•ì¸
if ! pg_isready -h $PRIMARY_HOST; then
    echo "Primary server is down! Initiating failover..."
    
    # 2. Standbyë¥¼ Primaryë¡œ ìŠ¹ê²©
    ssh $STANDBY_HOST "sudo -u postgres pg_ctl promote -D /var/lib/postgresql/data"
    
    # 3. ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì • ë³€ê²½
    sed -i "s/$PRIMARY_HOST/$STANDBY_HOST/g" /opt/glimpse/.env.production
    
    # 4. ì• í”Œë¦¬ì¼€ì´ì…˜ ì¬ì‹œì‘
    systemctl restart glimpse-api
    
    # 5. DNS ì—…ë°ì´íŠ¸ ë˜ëŠ” ë¡œë“œ ë°¸ëŸ°ì„œ ì„¤ì • ë³€ê²½
    aws route53 change-resource-record-sets --hosted-zone-id $ZONE_ID \
        --change-batch file://failover-dns.json
    
    echo "Failover completed!"
fi
```

### 3. ë¶€ë¶„ ë³µêµ¬

#### 3.1 íŠ¹ì • í…Œì´ë¸” ë³µêµ¬
```bash
#!/bin/bash
# /opt/glimpse/scripts/restore-table.sh

TABLE_NAME=$1
BACKUP_FILE=$2

# í…Œì´ë¸”ë§Œ ì¶”ì¶œ
pg_restore -h $DB_HOST -U $DB_USER -d glimpse_temp -t $TABLE_NAME $BACKUP_FILE

# ë°ì´í„° ë¹„êµ
echo "Current data:"
psql -h $DB_HOST -U $DB_USER -d glimpse_prod -c "SELECT COUNT(*) FROM $TABLE_NAME"

echo "Backup data:"
psql -h $DB_HOST -U $DB_USER -d glimpse_temp -c "SELECT COUNT(*) FROM $TABLE_NAME"

# ë³µêµ¬ ì˜µì…˜
echo "1. Replace entire table"
echo "2. Merge missing records"
echo "3. Cancel"
read -p "Select option: " option

case $option in
    1)
        psql -h $DB_HOST -U $DB_USER -d glimpse_prod << EOF
        BEGIN;
        TRUNCATE TABLE $TABLE_NAME CASCADE;
        INSERT INTO $TABLE_NAME SELECT * FROM glimpse_temp.$TABLE_NAME;
        COMMIT;
EOF
        ;;
    2)
        psql -h $DB_HOST -U $DB_USER -d glimpse_prod << EOF
        BEGIN;
        INSERT INTO $TABLE_NAME 
        SELECT * FROM glimpse_temp.$TABLE_NAME t
        WHERE NOT EXISTS (
            SELECT 1 FROM $TABLE_NAME WHERE id = t.id
        );
        COMMIT;
EOF
        ;;
esac
```

#### 3.2 íŠ¹ì • ì‚¬ìš©ì ë°ì´í„° ë³µêµ¬
```bash
#!/bin/bash
# /opt/glimpse/scripts/restore-user-data.sh

USER_ID=$1
BACKUP_DATE=$2

# ì‚¬ìš©ì ê´€ë ¨ í…Œì´ë¸” ëª©ë¡
TABLES=(
    "users"
    "user_profiles"
    "likes"
    "matches"
    "messages"
    "user_groups"
    "user_preferences"
)

# ì„ì‹œ ìŠ¤í‚¤ë§ˆ ìƒì„±
psql -h $DB_HOST -U $DB_USER -d glimpse_prod -c "CREATE SCHEMA recovery_temp;"

# ê° í…Œì´ë¸”ì—ì„œ ì‚¬ìš©ì ë°ì´í„° ë³µêµ¬
for table in "${TABLES[@]}"; do
    echo "Restoring $table for user $USER_ID..."
    
    # ë°±ì—…ì—ì„œ ë°ì´í„° ì¶”ì¶œ
    pg_restore -h $DB_HOST -U $DB_USER -d glimpse_prod \
        --schema=recovery_temp \
        -t $table \
        $BACKUP_FILE
    
    # ì‚¬ìš©ì ë°ì´í„°ë§Œ ë³µì‚¬
    case $table in
        "users"|"user_profiles"|"user_preferences")
            WHERE_CLAUSE="WHERE id = '$USER_ID'"
            ;;
        "likes")
            WHERE_CLAUSE="WHERE from_user_id = '$USER_ID' OR to_user_id = '$USER_ID'"
            ;;
        "matches")
            WHERE_CLAUSE="WHERE user1_id = '$USER_ID' OR user2_id = '$USER_ID'"
            ;;
        "messages")
            WHERE_CLAUSE="WHERE sender_id = '$USER_ID' OR receiver_id = '$USER_ID'"
            ;;
        "user_groups")
            WHERE_CLAUSE="WHERE user_id = '$USER_ID'"
            ;;
    esac
    
    psql -h $DB_HOST -U $DB_USER -d glimpse_prod << EOF
    INSERT INTO $table 
    SELECT * FROM recovery_temp.$table 
    $WHERE_CLAUSE
    ON CONFLICT (id) DO UPDATE SET
        updated_at = EXCLUDED.updated_at;
EOF
done

# ì„ì‹œ ìŠ¤í‚¤ë§ˆ ì‚­ì œ
psql -h $DB_HOST -U $DB_USER -d glimpse_prod -c "DROP SCHEMA recovery_temp CASCADE;"
```

## ğŸ“Š ë°±ì—… ëª¨ë‹ˆí„°ë§

### 1. ë°±ì—… ìƒíƒœ ëŒ€ì‹œë³´ë“œ
```sql
-- ë°±ì—… ëª¨ë‹ˆí„°ë§ ë·°
CREATE VIEW v_backup_status AS
SELECT 
    backup_date,
    backup_type,
    file_size_mb,
    duration_seconds,
    status,
    error_message,
    s3_uploaded,
    verified
FROM backup_logs
WHERE backup_date >= CURRENT_DATE - INTERVAL '7 days'
ORDER BY backup_date DESC;

-- ë°±ì—… í†µê³„
CREATE VIEW v_backup_statistics AS
SELECT 
    backup_type,
    COUNT(*) as total_backups,
    AVG(file_size_mb) as avg_size_mb,
    AVG(duration_seconds) as avg_duration_sec,
    SUM(CASE WHEN status = 'SUCCESS' THEN 1 ELSE 0 END) as successful,
    SUM(CASE WHEN status = 'FAILED' THEN 1 ELSE 0 END) as failed
FROM backup_logs
WHERE backup_date >= CURRENT_DATE - INTERVAL '30 days'
GROUP BY backup_type;
```

### 2. ì•Œë¦¼ ì„¤ì •
```bash
#!/bin/bash
# /opt/glimpse/scripts/backup-monitor.sh

# ìµœê·¼ ë°±ì—… í™•ì¸
LAST_BACKUP=$(psql -h $DB_HOST -U $DB_USER -d glimpse_prod -t -c "
    SELECT MAX(backup_date) 
    FROM backup_logs 
    WHERE status = 'SUCCESS' AND backup_type = 'daily'
")

# 24ì‹œê°„ ì´ìƒ ë°±ì—…ì´ ì—†ìœ¼ë©´ ì•Œë¦¼
HOURS_SINCE_BACKUP=$(psql -h $DB_HOST -U $DB_USER -d glimpse_prod -t -c "
    SELECT EXTRACT(EPOCH FROM (NOW() - MAX(backup_date)))/3600 
    FROM backup_logs 
    WHERE status = 'SUCCESS' AND backup_type = 'daily'
")

if (( $(echo "$HOURS_SINCE_BACKUP > 24" | bc -l) )); then
    # PagerDuty ì•Œë¦¼
    curl -X POST https://events.pagerduty.com/v2/enqueue \
        -H 'Content-Type: application/json' \
        -d "{
            \"routing_key\": \"$PAGERDUTY_KEY\",
            \"event_action\": \"trigger\",
            \"payload\": {
                \"summary\": \"Database backup missing for >24 hours\",
                \"severity\": \"error\",
                \"source\": \"glimpse-backup-monitor\"
            }
        }"
fi
```

## ğŸ”§ ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œì™€ í•´ê²° ë°©ë²•

#### 1. ë°±ì—… ì‹¤íŒ¨
```bash
# ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
df -h /backup

# PostgreSQL ë¡œê·¸ í™•ì¸
tail -f /var/log/postgresql/postgresql-*.log

# ê¶Œí•œ í™•ì¸
ls -la /backup/postgres/

# ì—°ê²° í…ŒìŠ¤íŠ¸
pg_isready -h $DB_HOST -U $DB_USER
```

#### 2. ë³µì› ì‹¤íŒ¨
```bash
# ì—ëŸ¬ ë©”ì‹œì§€ í™•ì¸
pg_restore -v -h $DB_HOST -U $DB_USER -d glimpse_test backup.dump 2>&1 | tee restore.log

# ì˜ì¡´ì„± ë¬¸ì œ í•´ê²°
pg_restore --no-owner --no-privileges --no-tablespaces

# ë¶€ë¶„ ë³µì›
pg_restore --section=pre-data
pg_restore --section=data
pg_restore --section=post-data
```

#### 3. ì„±ëŠ¥ ë¬¸ì œ
```bash
# ë³‘ë ¬ ì²˜ë¦¬ ì‚¬ìš©
pg_dump -j 4  # 4ê°œ ë³‘ë ¬ ì‘ì—…
pg_restore -j 4

# ì••ì¶• ë ˆë²¨ ì¡°ì •
pg_dump --compress=6  # ê¸°ë³¸ê°’ 9ë³´ë‹¤ ë¹ ë¦„

# ëŒ€ìš©ëŸ‰ í…Œì´ë¸” ì œì™¸
pg_dump --exclude-table=audit_logs
```

## ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì¼ì¼ ì ê²€
- [ ] ë°±ì—… ì‘ì—… ì„±ê³µ ì—¬ë¶€ í™•ì¸
- [ ] ë°±ì—… íŒŒì¼ í¬ê¸° ì •ìƒ ì—¬ë¶€
- [ ] S3 ì—…ë¡œë“œ ì™„ë£Œ í™•ì¸
- [ ] ë””ìŠ¤í¬ ê³µê°„ í™•ì¸

### ì£¼ê°„ ì ê²€
- [ ] ë°±ì—… ë³µì› í…ŒìŠ¤íŠ¸
- [ ] WAL ì•„ì¹´ì´ë¸Œ ìƒíƒœ í™•ì¸
- [ ] ë°±ì—… ë¡œê·¸ ë¶„ì„
- [ ] ìŠ¤í† ë¦¬ì§€ ì‚¬ìš©ëŸ‰ ì¶”ì„¸ í™•ì¸

### ì›”ê°„ ì ê²€
- [ ] ì „ì²´ ë³µêµ¬ ì‹œë®¬ë ˆì´ì…˜
- [ ] DR ì‚¬ì´íŠ¸ ë™ê¸°í™” í™•ì¸
- [ ] ë°±ì—… ì •ì±… ê²€í† 
- [ ] ë³µêµ¬ ì ˆì°¨ ë¬¸ì„œ ì—…ë°ì´íŠ¸

## ğŸš¨ ë¹„ìƒ ì—°ë½ì²˜

### ë°ì´í„°ë² ì´ìŠ¤ íŒ€
- **DBA Lead**: +82-10-XXXX-XXXX
- **ë°±ì—… ë‹´ë‹¹ì**: +82-10-XXXX-XXXX
- **ì•¼ê°„ ë‹¹ì§**: +82-10-XXXX-XXXX

### ì™¸ë¶€ ì§€ì›
- **AWS Support**: https://console.aws.amazon.com/support
- **PostgreSQL ì»¨ì„¤íŒ…**: support@postgresql.kr