input {
  # Receive logs from Filebeat
  beats {
    port => 5044
  }

  # Receive JSON logs via TCP
  tcp {
    port => 5000
    codec => json
  }

  # Receive syslog
  syslog {
    port => 5514
    type => "syslog"
  }
}

filter {
  # Parse JSON logs from Node.js applications
  if [fields][service] == "backend" {
    json {
      source => "message"
      target => "app"
    }
    
    # Extract useful fields
    mutate {
      add_field => {
        "log_level" => "%{[app][level]}"
        "timestamp" => "%{[app][timestamp]}"
        "service_name" => "%{[app][service]}"
      }
    }

    # Parse HTTP request logs
    if [app][req] {
      mutate {
        add_field => {
          "http_method" => "%{[app][req][method]}"
          "http_path" => "%{[app][req][url]}"
          "http_status" => "%{[app][res][statusCode]}"
          "response_time" => "%{[app][responseTime]}"
        }
      }
    }

    # Parse error logs
    if [app][err] {
      mutate {
        add_field => {
          "error_message" => "%{[app][err][message]}"
          "error_stack" => "%{[app][err][stack]}"
        }
      }
    }
  }

  # Parse Nginx access logs
  if [fields][service] == "nginx" {
    grok {
      match => {
        "message" => "%{COMBINEDAPACHELOG}"
      }
    }
    
    # Convert response time to float
    mutate {
      convert => {
        "response" => "float"
        "bytes" => "integer"
      }
    }
    
    # GeoIP lookup for client IP
    geoip {
      source => "clientip"
      target => "geoip"
    }
  }

  # Parse PostgreSQL logs
  if [fields][service] == "postgres" {
    grok {
      match => {
        "message" => "%{TIMESTAMP_ISO8601:timestamp} %{WORD:timezone} \[%{NUMBER:pid}\] %{WORD:log_level}: %{GREEDYDATA:query}"
      }
    }
  }

  # Add common fields
  mutate {
    add_field => {
      "environment" => "${NODE_ENV:production}"
      "application" => "glimpse"
    }
  }

  # Remove sensitive data
  mutate {
    remove_field => ["[app][req][headers][authorization]", "[app][req][headers][cookie]", "password", "token"]
  }

  # Convert timestamps
  date {
    match => ["timestamp", "ISO8601", "yyyy-MM-dd HH:mm:ss.SSS"]
    target => "@timestamp"
  }
}

output {
  # Send to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "glimpse-%{[fields][service]}-%{+YYYY.MM.dd}"
    template_name => "glimpse"
    template => "/usr/share/logstash/templates/glimpse.json"
    template_overwrite => true
  }

  # Debug output (remove in production)
  if [log_level] == "ERROR" or [log_level] == "error" {
    stdout {
      codec => rubydebug
    }
  }

  # Send critical errors to monitoring
  if [log_level] == "ERROR" or [http_status] >= 500 {
    http {
      url => "http://backend:3001/api/v1/monitoring/alert"
      http_method => "post"
      format => "json"
      mapping => {
        "level" => "%{log_level}"
        "service" => "%{[fields][service]}"
        "message" => "%{message}"
        "timestamp" => "%{@timestamp}"
      }
    }
  }
}